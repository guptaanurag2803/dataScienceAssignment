{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b527dbf7",
   "metadata": {},
   "source": [
    "#1.\n",
    "\n",
    "Bayes theorem states that the probability of event A occurring given that event B has occurred is equal to the probability of event B occurring given that event A has occurred, multiplied by the prior probability of event A, divided by the probability of event B."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c155f458",
   "metadata": {},
   "source": [
    "#2.\n",
    "\n",
    "Bayes' theorem can be expressed as:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the probability of event A occurring given that event B has occurred. This is called the posterior probability.\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred. This is called the likelihood.\n",
    "P(A) is the probability of event A occurring. This is called the prior probability.\n",
    "P(B) is the probability of event B occurring."
   ]
  },
  {
   "cell_type": "raw",
   "id": "32ac2419",
   "metadata": {},
   "source": [
    "#3.\n",
    "\n",
    "Let's consider a bayes theorem example is described to illustrate the use of Bayes theorem in a problem.\n",
    "\n",
    "Problem\n",
    "\n",
    "Three boxes labeled as A, B, and C, are present. Details of the boxes are:\n",
    "\n",
    "Box A contains 2 red and 3 black balls\n",
    "Box B contains 3 red and 1 black ball\n",
    "And box C contains 1 red ball and 4 black balls\n",
    "All the three boxes are identical having an equal probability to be picked up. Therefore, what is the probability that the red ball was picked up from box A?\n",
    "\n",
    "Solution\n",
    "\n",
    "Let E denote the event that a red ball is picked up and A, B and C denote that the ball is picked up from their respective boxes. Therefore the conditional probability would be P(A|E) which needs to be calculated.\n",
    "\n",
    "The existing probabilities P(A) = P(B) = P (C) = 1 / 3, since all boxes have equal probability of getting picked.\n",
    "\n",
    "P(E|A) = Number of red balls in box A / Total number of balls in box A = 2 / 5\n",
    "\n",
    "Similarly, P(E|B) = 3 / 4 and P(E|C) = 1 / 5\n",
    "\n",
    "Then evidence P(E) = P(E|A)*P(A) + P(E|B)*P(B) + P(E|C)*P(C) \n",
    "\n",
    "                   = (2/5) * (1/3) + (3/4) * (1/3) + (1/5) * (1/3) = 0.45\n",
    "\n",
    "Therefore, P(A|E) = P(E|A) * P(A) / P(E) = (2/5) * (1/3) / 0.45 = 0.296"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bff798e9",
   "metadata": {},
   "source": [
    "#4.\n",
    "\n",
    "The relationship between Bayes' theorem and conditional probability can be understood by examining the formula for Bayes' theorem:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the conditional probability of event A occurring given that event B has occurred. This is called the posterior probability.\n",
    "P(B|A) is the conditional probability of event B occurring given that event A has occurred. This is called the likelihood.\n",
    "P(A) is the prior probability of event A occurring. This is the probability of event A before considering any new evidence.\n",
    "P(B) is the probability of event B occurring.\n",
    "Now, consider the relationship with conditional probability:\n",
    "\n",
    "P(A|B) = P(A ∩ B) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A ∩ B) is the probability of both events A and B occurring together. This is the joint probability of events A and B.\n",
    "P(B) is the probability of event B occurring.\n",
    "The relationship becomes evident when we consider that the joint probability can be expressed using conditional probability:\n",
    "\n",
    "P(A ∩ B) = P(B|A) * P(A)\n",
    "\n",
    "Substituting this into the Bayes' theorem formula:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "which matches the definition of conditional probability."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a339649a",
   "metadata": {},
   "source": [
    "#5.\n",
    "\n",
    "There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here's a brief overview of each and some guidance on how to choose:\n",
    "\n",
    "A. Gaussian Naive Bayes:\n",
    "Assumes that the features follow a Gaussian (normal) distribution.\n",
    "Suitable for continuous numerical features.\n",
    "Typically used when the features are real-valued or have a large number of distinct values.\n",
    "Use Gaussian Naive Bayes when:\n",
    "\n",
    "Your features are continuous and have a reasonably normal distribution.\n",
    "Your data is real-valued and has a large number of distinct values.\n",
    "\n",
    "B. Multinomial Naive Bayes:\n",
    "Assumes that the features are discrete and represent counts (e.g., word counts in text data).\n",
    "Suitable for categorical or count-based features.\n",
    "Commonly used in text classification tasks.\n",
    "Use Multinomial Naive Bayes when:\n",
    "\n",
    "Your features are discrete and represent counts or frequencies.\n",
    "Your data is in the form of word frequencies or document-term matrices (common in text classification).\n",
    "\n",
    "C. Bernoulli Naive Bayes:\n",
    "Assumes that the features are binary (1 or 0).\n",
    "Suitable for binary features or features that can be easily binarized.\n",
    "Often used in problems like sentiment analysis or document classification.\n",
    "Use Bernoulli Naive Bayes when:\n",
    "\n",
    "Your features are binary (e.g., presence/absence of certain words in a document).\n",
    "Your data can be represented in binary form (e.g., bag-of-words features in text data)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b3e3b3a",
   "metadata": {},
   "source": [
    "#6.\n",
    "\n",
    "To predict the class of the new instance (X1=3 and X2=4) using Naive Bayes, we need to calculate the likelihoods for each class and then apply Bayes' theorem to find the posterior probabilities. Since we are assuming equal prior probabilities for each class, the prior probabilities will be P(A) = P(B) = 0.5.\n",
    "\n",
    "For Class A:\n",
    "- P(X1=3 | A) = 4/13\n",
    "- P(X2=4 | A) = 3/13\n",
    "\n",
    "For Class B:\n",
    "P(X1=3 | B) = 1/7\n",
    "P(X2=4 | B) = 3/7\n",
    "\n",
    "we need to calculate the value of P(X1=3, X2=4):\n",
    "P(X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) + P(X1=3, X2=4 | B) * P(B)\n",
    "P(X1=3, X2=4) = (4/13 * 3/13 * 0.5) + (1/7 * 3/7 * 0.5)\n",
    "P(X1=3, X2=4) ≈ 0.059543\n",
    "\n",
    "Now, let's apply Bayes' theorem to calculate the posterior probabilities:\n",
    "\n",
    "For Class A:\n",
    "P(A | X1=3, X2=4) = (P(X1=3 | A) * P(X2=4 | A) * P(A)) / P(X1=3, X2=4)\n",
    "\n",
    "P(A | X1=3, X2=4) = (4/13 * 3/13 * 0.5) / P(X1=3, X2=4)\n",
    "\n",
    "For Class B:\n",
    "P(B | X1=3, X2=4) = (P(X1=3 | B) * P(X2=4 | B) * P(B)) / P(X1=3, X2=4)\n",
    "\n",
    "P(B | X1=3, X2=4) = (1/7 * 3/7 * 0.5) / P(X1=3, X2=4)\n",
    "\n",
    "Now, \n",
    "\n",
    "After calculating, we find that:\n",
    "\n",
    "\n",
    "Now, we can calculate the posterior probabilities:\n",
    "\n",
    "P(A | X1=3, X2=4) ≈ (4/13 * 3/13 * 0.5) / 0.059543 ≈ 0.2552\n",
    "\n",
    "P(B | X1=3, X2=4) ≈ (1/7 * 3/7 * 0.5) / 0.059543 ≈ 0.7448\n",
    "\n",
    "The posterior probability for Class B is higher, so Naive Bayes would predict the new instance to belong to Class B."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
