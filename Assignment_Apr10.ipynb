{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b2b275",
   "metadata": {},
   "source": [
    "#1.\n",
    "\n",
    "X = the employees use the company's health insurance plan\n",
    "Y = employee is smoker\n",
    "\n",
    "P(X) = .70\n",
    "P(X and Y) = .40\n",
    "\n",
    "Probability that an employee is a smoker given that he/she uses the health insurance plan:\n",
    "P(Y/X) = P(X and Y)/P(X) = .40/.70 = 0.5714"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bddda2",
   "metadata": {},
   "source": [
    "#2.\n",
    "\n",
    "Bernoulli Naive Bayes:\n",
    "a. Suitable for binary or boolean features (i.e., features that take on only two values, typically 0 and 1).\n",
    "b. Assumes that each feature is independent of all other features, given the class label.\n",
    "c. Commonly used in text classification tasks where the presence or absence of words is represented as binary features (e.g., bag-of-words model).\n",
    "d. The model is named after the Bernoulli distribution, which models binary outcomes.\n",
    "\n",
    "Multinomial Naive Bayes:\n",
    "a. Suitable for discrete features that represent counts or frequencies (e.g., word frequencies in a document).\n",
    "b. Assumes that each feature is a count of the occurrences of a particular event (word or term) and follows a multinomial distribution.\n",
    "c. Widely used in text classification tasks where features are represented as frequency counts (e.g., document-term matrices).\n",
    "d. Multinomial Naive Bayes considers the frequency of each term as opposed to just presence or absence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d351f1b",
   "metadata": {},
   "source": [
    "#3.\n",
    "\n",
    "Bernoulli Naive Bayes is a binary classification algorithm where features are represented as 0 or 1, indicating absence or presence of an attribute. When faced with missing values, it treats them as a third category (e.g., \"?\") to handle the uncertainty associated with the missing data.\n",
    "\n",
    "During training, the algorithm estimates probabilities for each feature's presence (1), absence (0), and missing value (?), given each class, based on observed data. When making predictions for new instances with missing values, it uses these probabilities to calculate the likelihood of each class.\n",
    "\n",
    "However, dealing with missing data effectively is a challenge in any machine learning algorithm, including Bernoulli Naive Bayes. The handling of missing values should be carefully considered, as the approach taken can impact model performance. Some common strategies include imputation techniques (e.g., filling missing values with the mean or median), using the Expectation-Maximization (EM) algorithm to estimate missing data, or considering additional features to indicate the presence of missing values.\n",
    "\n",
    "Selecting the appropriate approach depends on the specific problem, data distribution, and the level of missingness in the dataset. Overall, addressing missing values is crucial for ensuring the accuracy and reliability of the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42326a1d",
   "metadata": {},
   "source": [
    "#4.\n",
    "\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. In Gaussian Naive Bayes, the algorithm assumes that the features follow a Gaussian (normal) distribution, and it can handle continuous numerical features. When dealing with multi-class problems, Gaussian Naive Bayes extends naturally to accommodate multiple classes.\n",
    "\n",
    "During training, the algorithm calculates the mean and standard deviation of each feature for each class. It then uses this information to model the distribution of each feature for each class as a Gaussian distribution. When making predictions on new instances with multiple classes, it calculates the likelihood of the feature values for each class based on their respective Gaussian distributions.\n",
    "\n",
    "The class with the highest likelihood (product of likelihoods of all features) is considered the predicted class for the new instance. In this way, Gaussian Naive Bayes can be effectively used for multi-class classification tasks, where each instance is assigned to one of multiple possible classes based on the Gaussian distribution of its feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5166312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "column_names = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'is_spam'\n",
    "                ]\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv('spambase.data', names=column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a72d805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88646af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_#                   0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "is_spam                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42d2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd17799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy:  0.8839380364047911\n",
      "Multinomial Naive Bayes Accuracy:  0.7863496180326323\n",
      "Gaussian Naive Bayes Accuracy:  0.8217730830896915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "scores_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10)\n",
    "scores_multinomial = cross_val_score(multinomial_nb, X, y, cv=10)\n",
    "scores_gaussian = cross_val_score(gaussian_nb, X, y, cv=10)\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Accuracy: \", (scores_bernoulli.mean()))\n",
    "print(\"Multinomial Naive Bayes Accuracy: \", (scores_multinomial.mean()))\n",
    "print(\"Gaussian Naive Bayes Accuracy: \", (scores_gaussian.mean()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
