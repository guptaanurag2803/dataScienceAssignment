{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92490d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_csv('dataset.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03734b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f50ee451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a47d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a80a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4190a2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebffe78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e99d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9521966 ,  0.68100522,  1.97312292, ..., -2.27457861,\n",
       "        -0.71442887, -2.14887271],\n",
       "       [-1.91531289,  0.68100522,  1.00257707, ..., -2.27457861,\n",
       "        -0.71442887, -0.51292188],\n",
       "       [-1.47415758, -1.46841752,  0.03203122, ...,  0.97635214,\n",
       "        -0.71442887, -0.51292188],\n",
       "       ...,\n",
       "       [ 1.50364073,  0.68100522, -0.93851463, ..., -0.64911323,\n",
       "         1.24459328,  1.12302895],\n",
       "       [ 0.29046364,  0.68100522, -0.93851463, ..., -0.64911323,\n",
       "         0.26508221,  1.12302895],\n",
       "       [ 0.29046364, -1.46841752,  0.03203122, ..., -0.64911323,\n",
       "         0.26508221, -0.51292188]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c91c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dafc8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random = RandomForestClassifier(max_depth=10, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3912c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8470c143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = random.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1ee7c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8241758241758241\n",
      "0.7924528301886793\n",
      "0.8936170212765957\n",
      "0.8400000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb09d3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08521438, 0.04725807, 0.12166308, 0.07017755, 0.08208504,\n",
       "       0.01044399, 0.01794215, 0.11306314, 0.05810176, 0.13593083,\n",
       "       0.04401096, 0.11102823, 0.10308082])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = random.feature_importances_\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ec43339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "top5 = np.argsort(feature_importance)[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4694ab03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAIjCAYAAABCh/k6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABRUElEQVR4nO3de3zP9f//8ft7m713ss2ZOWzYaM7llDlMEcKIj1TkGKX4SDWnHDJyyMcxp0ShvskhRSk5UwlJlDRChrQoMeawsT1/f/TbO2/b2GazXna7Xi7vi71f7+f79X4838/3+2X3PV8HmzHGCAAAAADwr+eS2wUAAAAAADKGAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAgAWdOnVKHTp0UKFChWSz2TRt2rTcLumu1r17dwUFBeV2GXe9mJgY2Ww2LVy40LFs1KhRstls2fYaW7Zskc1m05YtW7JtncCdRIADLMRms2Xodif+U0rvtSdMmHDL5y5cuNDR/quvvkr1uDFGpUuXls1mU+vWrXOifP32228aNWqU9u7dm6H2KTV/++23OVLPnTB79mynX4py0uLFizMVKIKCgtL9TF25ciVHahw3bpxWrlyZI+u+E1544QWtXbtWQ4cO1bvvvqsWLVrk6OvZbDb169cvzcdy+/vx008/adSoUYqJiclQ+5RAkHLz8vJSmTJlFBERoQULFighISFnC/4X6969u9N74+vrq+rVq2vy5MmWe1/u5DYPuJPccrsAABn37rvvOt1/5513tH79+lTLQ0ND70g9Dz30kLp27eq07N57783w8z08PLR48WI1aNDAafnWrVv166+/ym63Z0udafntt98UFRWloKAg1ahRI8de599k9uzZKly4sLp3757jr7V48WL9+OOPGjBgQIafU6NGDb300kuplru7u2djZf8YN26cOnTooEceeSRH1p/TNm3apLZt2yoyMjK3S8l1P/30k6KiotS4ceNMzZLNmTNHPj4+SkhI0MmTJ7V27Vr17NlT06ZN0+rVq1W6dGlH23nz5ik5OTkHqv/3sdvtmj9/viTp3LlzWrFihSIjI7Vr1y4tWbLkjtczfPhwDRkyJNPPS2+b16hRI12+fDnHti1ATiPAARby5JNPOt3fsWOH1q9fn2r5nVKhQoXbeu2WLVtq+fLlev311+Xm9s/maPHixapZs6b+/PPP7Cgzz7t06ZK8vLxyu4xbKlmyZK59lrNLcnKyEhMT5eHhkeOvdfr0afn7+2fb+q5cuSJ3d3e5uFhn55yUmrOqQ4cOKly4sOP+yJEj9d5776lr16569NFHtWPHDsdj+fLlu61arcTNzc3pu/jcc8+pbt26Wrp0qaZMmaKAgIBUzzHG6MqVK/L09MyReq7/P+J2ubi43JHvKJBTrLOVBpAhFy9e1EsvvaTSpUvLbrerYsWKmjRpkowxTu1Sdod67733VLFiRXl4eKhmzZr64osvMvV6ly9fzvIubk888YTOnDmj9evXO5YlJibqgw8+UKdOndJ8Tkb7t379ejVo0ED+/v7y8fFRxYoV9fLLL0v6+/iH2rVrS5J69Ojh2FUos7vadO/eXT4+Pjp+/Lhat24tHx8flSxZUrNmzZIk7du3Tw8++KC8vb0VGBioxYsXOz0/ZbezL774Qs8884wKFSokX19fde3aVWfPnk31erNnz1blypVlt9sVEBCgvn376ty5c05tGjdurCpVqmj37t1q1KiRvLy89PLLLysoKEj79+/X1q1bHf1t3LixJOmvv/5SZGSkqlatKh8fH/n6+urhhx/W999/77TulONGli1bprFjx6pUqVLy8PBQkyZNdPjwYacaPv30Ux07dszxWtlx7NC5c+c0YMAAx9gHBwfrtddeSzUrMmnSJIWFhalQoULy9PRUzZo19cEHHzi1sdlsunjxohYtWuSoMeWv9Okd65TWcTjXf49Sxubzzz+XJJ08eVI9e/ZUsWLFZLfbVblyZb399tup1jtjxgxVrlxZXl5eKlCggGrVqpXqs3K9lM+NMUazZs1y1J/il19+0aOPPqqCBQvKy8tL999/vz799FOndaSM5ZIlSzR8+HCVLFlSXl5eOn/+fLqvmxUHDhxQhw4dVLBgQXl4eKhWrVr6+OOPndpk9vN3Y82vv/66Hn30UUnSAw88cNu7knfu3Fm9evXSzp07nbZNaX0ulixZopo1ayp//vzy9fVV1apVNX36dKc22fm5lW6+bUuRkJCgV155RcHBwbLb7SpdurQGDRqU5V0gXVxcHNuLlN1Ug4KC1Lp1a61du1a1atWSp6en5s6dm6k+nzt3Tt27d5efn5/8/f3VrVu3VNs0Kf1j4P7v//5PderUcXx3GjVqpHXr1jnqS2+bl94xcMuXL1fNmjXl6empwoUL68knn9TJkyed2qRs90+ePKlHHnlEPj4+KlKkiCIjI5WUlJTJdxbIGmbggLuIMUZt2rTR5s2b9dRTT6lGjRpau3atBg4cqJMnT2rq1KlO7bdu3aqlS5eqf//+stvtmj17tlq0aKFvvvlGVapUueXrLVy4ULNnz5YxRqGhoRo+fHi6wSstQUFBqlevnt5//309/PDDkqQ1a9YoLi5Ojz/+uF5//fUs9W///v1q3bq1qlWrptGjR8tut+vw4cPatm2bpL93MR09erRGjhypp59+Wg0bNpQkhYWFZbj2FElJSXr44YfVqFEjTZw4Ue+995769esnb29vDRs2TJ07d1b79u31xhtvqGvXrqpXr57Kli3rtI5+/frJ399fo0aN0sGDBzVnzhwdO3bM8UuG9PcvMFFRUWratKmeffZZR7tdu3Zp27ZtTrMDZ86c0cMPP6zHH39cTz75pIoVK6bGjRvrv//9r3x8fDRs2DBJUrFixST9/Qv/ypUr9eijj6ps2bI6deqU5s6dq/DwcP3000+p/to+YcIEubi4KDIyUnFxcZo4caI6d+6snTt3SpKGDRumuLg4/frrr44x8fHxueV7efXq1VSzrl5eXvLy8tKlS5cUHh6ukydP6plnnlGZMmX09ddfa+jQoYqNjXU63m769Olq06aNOnfurMTERC1ZskSPPvqoVq9erVatWkn6e3fkXr16qU6dOnr66aclSeXLl79ljWnZtGmTli1bpn79+qlw4cIKCgrSqVOndP/99zsCXpEiRbRmzRo99dRTOn/+vGPX0nnz5ql///7q0KGDnn/+eV25ckU//PCDdu7cme53qVGjRnr33XfVpUuXVLsxnzp1SmFhYbp06ZL69++vQoUKadGiRWrTpo0++OADtWvXzmldY8aMkbu7uyIjI5WQkHDL2awrV66kOTMeHx+fatn+/ftVv359lSxZUkOGDJG3t7eWLVumRx55RCtWrHDUktnP3401N2vWTP3799frr7+ul19+2bEL+e3sSt6lSxe9+eabWrdunR566KE026xfv15PPPGEmjRpotdee02SFB0drW3btun555+XpGz/3N5q2yb9PQvcpk0bffXVV3r66acVGhqqffv2aerUqfr555+zfNznkSNHJEmFChVyLDt48KCeeOIJPfPMM+rdu7cqVqyY4T4bY9S2bVt99dVX6tOnj0JDQ/XRRx+pW7duGaonKipKo0aNUlhYmEaPHi13d3ft3LlTmzZtUrNmzTRt2rR0t3lpWbhwoXr06KHatWtr/PjxOnXqlKZPn65t27Zpz549TrPdSUlJat68uerWratJkyZpw4YNmjx5ssqXL69nn302k+8skAUGgGX17dvXXP81XrlypZFkXn31Vad2HTp0MDabzRw+fNixTJKRZL799lvHsmPHjhkPDw/Trl27W752WFiYmTZtmlm1apWZM2eOqVKlipFkZs+efcvnLliwwEgyu3btMjNnzjT58+c3ly5dMsYY8+ijj5oHHnjAGGNMYGCgadWqVab7N3XqVCPJ/PHHH+nWsGvXLiPJLFiw4Jb13lhzim7duhlJZty4cY5lZ8+eNZ6ensZms5klS5Y4lh84cMBIMq+88kqqddasWdMkJiY6lk+cONFIMqtWrTLGGHP69Gnj7u5umjVrZpKSkhztZs6caSSZt99+27EsPDzcSDJvvPFGqj5UrlzZhIeHp1p+5coVp/UaY8zRo0eN3W43o0ePdizbvHmzkWRCQ0NNQkKCY/n06dONJLNv3z7HslatWpnAwMBUr5WewMBAx2fy+lvK+zVmzBjj7e1tfv75Z6fnDRkyxLi6uprjx487lqV8llIkJiaaKlWqmAcffNBpube3t+nWrVuqWrp165Zm7a+88oq58b9NScbFxcXs37/faflTTz1lSpQoYf7880+n5Y8//rjx8/Nz1Ni2bVtTuXLl1G9IBkgyffv2dVo2YMAAI8l8+eWXjmUXLlwwZcuWNUFBQY5xThnLcuXKpXq/bvZ6t7pd//1o0qSJqVq1qrly5YpjWXJysgkLCzMhISGOZZn9/KVV8/Lly40ks3nz5gz1JWUs09tGnD171khy2hbe+Ll4/vnnja+vr7l27Vq6r5Pdn9uMbNveffdd4+Li4vQZMMaYN954w0gy27ZtS/e5Kf309vY2f/zxh/njjz/M4cOHzbhx44zNZjPVqlVztEv5zn7++edZ6nPK9nzixImONteuXTMNGzZMtW2+8bt36NAh4+LiYtq1a5fqs5OcnOz4Ob1tXspnKeXzkpiYaIoWLWqqVKliLl++7Gi3evVqI8mMHDnS6f2R5PTZNMaYe++919SsWTPVawE5gV0ogbvIZ599JldXV/Xv399p+UsvvSRjjNasWeO0vF69eqpZs6bjfpkyZdS2bVutXbv2lruCpPyVuU2bNurTp492796tKlWq6OWXX9bly5czXHPHjh11+fJlrV69WhcuXNDq1avTnXnIaP9S/lK6atWqO3LSgV69ejl+9vf3V8WKFeXt7a2OHTs6llesWFH+/v765ZdfUj3/6aefdppBe/bZZ+Xm5qbPPvtMkrRhwwYlJiZqwIABTscn9e7dW76+vql2j7Pb7erRo0eG67fb7Y71JiUl6cyZM45ds7777rtU7Xv06OE0U5Myg5lW3zKjbt26Wr9+vdMtZXZp+fLlatiwoQoUKKA///zTcWvatKmSkpKcdv29/hics2fPKi4uTg0bNkyzL9khPDxclSpVctw3xmjFihWKiIiQMcap3ubNmysuLs5Ri7+/v3799Vft2rUrW2r57LPPVKdOHacTA/n4+Ojpp59WTEyMfvrpJ6f23bp1y9QxS23btk01RuvXr9fAgQOd2v3111/atGmTOnbsqAsXLjj6f+bMGTVv3lyHDh1y7JqW2c9fZmvOipQZ4wsXLqTbxt/fXxcvXnTazfJG2f25zci2bfny5QoNDdU999zj9JoPPvigJGnz5s237P/FixdVpEgRFSlSRMHBwXr55ZdVr149ffTRR07typYtq+bNm2epz5999pnc3NycZqxcXV313//+95b1rVy5UsnJyRo5cmSqYzazcrmBb7/9VqdPn9Zzzz3ndGxcq1atdM8996TaxkpSnz59nO43bNjwtreBQEaxCyVwFzl27JgCAgKUP39+p+UpuxIdO3bMaXlISEiqdVSoUEGXLl3SH3/8oeLFi2f4td3d3dWvXz9HmLvxzJLpKVKkiJo2barFixfr0qVLSkpKUocOHdJsm9H+PfbYY5o/f7569eqlIUOGqEmTJmrfvr06dOiQ7Sdo8PDwUJEiRZyW+fn5qVSpUql+kfDz80vz2LYbx8HHx0clSpRwHGuS0q+KFSs6tXN3d1e5cuVSjWvJkiUzdWKH5ORkTZ8+XbNnz9bRo0edwvv1u0ulKFOmjNP9AgUKSFKafcuMwoULq2nTpmk+dujQIf3www+p3usUp0+fdvy8evVqvfrqq9q7d6/TMT/ZeR2p6924S+wff/yhc+fO6c0339Sbb75503oHDx6sDRs2qE6dOgoODlazZs3UqVMn1a9fP0u1HDt2THXr1k21/PrvyPW7R99Y+62UKlUqzTH69ddfne4fPnxYxhiNGDFCI0aMSHNdp0+fVsmSJTP9+ctszVmRskvojdua6z333HNatmyZHn74YZUsWVLNmjVTx44dnS7nkN2f24xs2w4dOqTo6OgMvWZ6PDw89Mknn0j6O2CXLVtWpUqVStUurbHIaJ+PHTumEiVKpNq9+sbtXFqOHDkiFxcXpz+c3I70trGSdM8996S63E1a2/0CBQrc9jYQyCgCHIBsk3LK7b/++itTz+vUqZN69+6t33//XQ8//PBtn1nP09NTX3zxhTZv3qxPP/1Un3/+uZYuXaoHH3xQ69atk6ur622t/3rprSu95eaGk63khMzOTowbN04jRoxQz549NWbMGBUsWFAuLi4aMGBAmn/lz42+JScn66GHHtKgQYPSfLxChQqSpC+//FJt2rRRo0aNNHv2bJUoUUL58uXTggULbnpikOulF/TSm5W+8f1Oec+efPLJdI/nqVatmqS/g9XBgwe1evVqff7551qxYoVmz56tkSNHKioqKkP13o6cmslKeQ8iIyNTzdCkCA4OlpT5z19Oz75J0o8//uhUY1qKFi2qvXv3au3atVqzZo3WrFmjBQsWqGvXrlq0aJGk7P/cZmTblpycrKpVq2rKlClpvub1l0ZIj6ura7p/TLleWmOR0T5bWXb+HwJkBQEOuIsEBgZqw4YNunDhgtNfjg8cOOB4/HqHDh1KtY6ff/5ZXl5e6f719GZSdh/J7HPbtWunZ555Rjt27NDSpUvTbZeZ/rm4uKhJkyZq0qSJpkyZonHjxmnYsGHavHmzmjZtmmOzMVlx6NAhPfDAA4778fHxio2NVcuWLSX906+DBw+qXLlyjnaJiYk6evRohn7RktIPJh988IEeeOABvfXWW07Lz50753SK9czI7ve3fPnyio+Pv2VfV6xYIQ8PD61du9bpOoILFizIcI0FChRI80x4N850pqdIkSLKnz+/kpKSMjQ23t7eeuyxx/TYY48pMTFR7du319ixYzV06NBMn+o8MDBQBw8eTLU8vW1ATkn5nObLl++W70F2fP6y+/OWcm3N9MJnCnd3d0VERCgiIkLJycl67rnnNHfuXI0YMULBwcE58rm91batfPny+v7779WkSZNc2c5ltM+BgYHauHGj4uPjnWbh0vr8pvUaycnJ+umnn256Hc+M9v/6bWzKrqbX13OnvjdARnEMHHAXadmypZKSkjRz5kyn5VOnTpXNZnOc6THF9u3bnY6vOHHihFatWqVmzZrd9C+Mf/zxR6plFy5c0LRp01S4cGGn4+oywsfHR3PmzNGoUaMUERGRbruM9i+tGcCU/+RTdk3y9vaWpDR/Ub/T3nzzTV29etVxf86cObp27ZqjP02bNpW7u7tef/11p1mut956S3FxcY4z1N2Kt7d3mv11dXVNNXu2fPnyVKfPzgxvb2/FxcVl+fk36tixo7Zv3661a9emeuzcuXO6du2apL/7YrPZnGbLYmJi0jzzXnrvR/ny5RUXF6cffvjBsSw2NjbV8T/pcXV11X/+8x+tWLHCMZNzveu/P2fOnHF6zN3dXZUqVZIxxukzkVEtW7bUN998o+3btzuWXbx4UW+++aaCgoKybZezWylatKgaN26suXPnKjY2NtXj178H2fH5y87v8+LFizV//nzVq1dPTZo0SbfdjWPn4uLimFlN2c5k9+c2I9u2jh076uTJk5o3b16qtpcvX9bFixfT7VN2yGifW7ZsqWvXrmnOnDmOx5OSkjRjxoxbvsYjjzwiFxcXjR49OtUs7fWfpfS+4zeqVauWihYtqjfeeMNp99U1a9YoOjo6w9tY4E5hBg64i0REROiBBx7QsGHDFBMTo+rVq2vdunVatWqVBgwYkOo06VWqVFHz5s2dLiMg6Za7bs2aNUsrV65URESEypQpo9jYWL399ts6fvy43n333SxdWDcjp47OaP9Gjx6tL774Qq1atVJgYKBOnz6t2bNnq1SpUo5j88qXLy9/f3+98cYbyp8/v7y9vVW3bt07cnzNjRITE9WkSRN17NhRBw8e1OzZs9WgQQO1adNG0t8zOkOHDlVUVJRatGihNm3aONrVrl07wxe/rlmzpubMmaNXX31VwcHBKlq0qB588EG1bt1ao0ePVo8ePRQWFqZ9+/bpvffec5rty6yaNWtq6dKlevHFF1W7dm35+PjcNJzfysCBA/Xxxx+rdevW6t69u2rWrKmLFy9q3759+uCDDxQTE6PChQurVatWmjJlilq0aKFOnTrp9OnTmjVrloKDg50CWUqNGzZscFyYuGzZsqpbt64ef/xxDR48WO3atVP//v116dIlzZkzRxUqVMjwiVAmTJigzZs3q27duurdu7cqVaqkv/76S9999502bNjg+EW8WbNmKl68uOrXr69ixYopOjpaM2fOVKtWrW56/FV6hgwZ4rgsR//+/VWwYEEtWrRIR48e1YoVK+7oRbpnzZqlBg0aqGrVqurdu7fKlSunU6dOafv27fr1118d13nLjs9fjRo15Orqqtdee01xcXGy2+168MEHVbRo0Zs+74MPPpCPj48SExN18uRJrV27Vtu2bVP16tW1fPnymz63V69e+uuvv/Tggw+qVKlSOnbsmGbMmKEaNWo4jjnM7s9tRrZtXbp00bJly9SnTx9t3rxZ9evXV1JSkg4cOKBly5Y5rtuWUzLa54iICNWvX19DhgxRTEyMKlWqpA8//DBDf/gJDg7WsGHDNGbMGDVs2FDt27eX3W7Xrl27FBAQoPHjx0tKf5t3o3z58um1115Tjx49FB4erieeeMJxGYGgoCC98MIL2f4+Abcld05+CSA73HgZAWP+PmX4Cy+8YAICAky+fPlMSEiI+d///ud0amVj/jkF+f/93/+ZkJAQY7fbzb333puh03CvW7fOPPTQQ6Z48eImX758xt/f3zRr1sxs3LgxQ3WndUr+tNx4GYGM9m/jxo2mbdu2JiAgwLi7u5uAgADzxBNPpDqt9apVq0ylSpWMm5vbLS8pkN5lBLy9vVO1DQ8PT/PU8Df2J2WdW7duNU8//bQpUKCA8fHxMZ07dzZnzpxJ9fyZM2eae+65x+TLl88UK1bMPPvss+bs2bMZem1jjPn9999Nq1atTP78+Y0kx+m1r1y5Yl566SVTokQJ4+npaerXr2+2b99uwsPDnU7BnXLq7eXLlzut9+jRo6nev/j4eNOpUyfj7+9vJN3ykgJpjfWNLly4YIYOHWqCg4ONu7u7KVy4sAkLCzOTJk1yugzDW2+95fhM33PPPWbBggVpXgLgwIEDplGjRsbT09NIcrqkwLp160yVKlWMu7u7qVixovm///u/dC8jcOOp/FOcOnXK9O3b15QuXdrky5fPFC9e3DRp0sS8+eabjjZz5841jRo1MoUKFTJ2u92UL1/eDBw40MTFxd30vbjZax85csR06NDB+Pv7Gw8PD1OnTh2zevVqpzbpjWVWXs+Y9L/TR44cMV27dnVsK0qWLGlat25tPvjgA0eb2/38pZg3b54pV66ccXV1veUlBVLGMuXm4eFhSpUqZVq3bm3efvttp0sfpLjxMgIffPCBadasmSlatKhxd3c3ZcqUMc8884yJjY11el52fm4zum1LTEw0r732mqlcubKx2+2mQIECpmbNmiYqKuqWn630tms3utl3NqN9PnPmjOnSpYvx9fU1fn5+pkuXLmbPnj23vIxAirffftvce++9jj6Gh4eb9evXOx5Pb5t342UEUixdutSxvoIFC5rOnTubX3/9NUPvT3o1AjnBZswdOKIewL+OzWZT3759U+2OiDsn5cKxu3btytG/iAMAgLsHx8ABAAAAgEUQ4AAAAADAIghwAAAAAGARHAMHAAAAABbBDBwAAAAAWAQBDgAAAAAsggt555Lk5GT99ttvyp8/v2w2W26XAwAAACCXGGN04cIFBQQEyMXl5nNsBLhc8ttvv6l06dK5XQYAAACAf4kTJ06oVKlSN21DgMsl+fPnl/T3IPn6+uZyNQAAAAByy/nz51W6dGlHRrgZAlwuSdlt0tfXlwAHAAAAIEOHVnESEwAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFiEW24XkNdVeWWtXOxeuV0GAAAAkGfETGiV2yVkGTNwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFvGvDXBbtmyRzWbTuXPn0m2zcOFC+fv737GaUowaNUo1atS4468LAAAAIG/71wY4AAAAAIAzAhwAAAAAWESuBriEhAT1799fRYsWlYeHhxo0aKBdu3al237hwoUqU6aMvLy81K5dO505c8bp8ZRdG+fOnavSpUvLy8tLHTt2VFxcnFO7+fPnKzQ0VB4eHrrnnns0e/Zsp8cHDx6sChUqyMvLS+XKldOIESN09erVdOs6cuSIypUrp379+skYk4V3AgAAAABuLVcD3KBBg7RixQotWrRI3333nYKDg9W8eXP99ddfqdru3LlTTz31lPr166e9e/fqgQce0Kuvvpqq3eHDh7Vs2TJ98skn+vzzz7Vnzx4999xzjsffe+89jRw5UmPHjlV0dLTGjRunESNGaNGiRY42+fPn18KFC/XTTz9p+vTpmjdvnqZOnZpmH3744Qc1aNBAnTp10syZM2Wz2dJsl5CQoPPnzzvdAAAAACAzci3AXbx4UXPmzNH//vc/Pfzww6pUqZLmzZsnT09PvfXWW6naT58+XS1atNCgQYNUoUIF9e/fX82bN0/V7sqVK3rnnXdUo0YNNWrUSDNmzNCSJUv0+++/S5JeeeUVTZ48We3bt1fZsmXVvn17vfDCC5o7d65jHcOHD1dYWJiCgoIUERGhyMhILVu2LNVrff3112rcuLEiIyPTDJPXGz9+vPz8/By30qVLZ/YtAwAAAJDH5VqAO3LkiK5evar69es7luXLl0916tRRdHR0qvbR0dGqW7eu07J69eqlalemTBmVLFnSqU1ycrIOHjyoixcv6siRI3rqqafk4+PjuL366qs6cuSI4zlLly5V/fr1Vbx4cfn4+Gj48OE6fvy40+scP35cDz30kEaOHKmXXnrplv0dOnSo4uLiHLcTJ07c8jkAAAAAcD233C7gToqPj5ckzZs3L1UYdHV1lSRt375dnTt3VlRUlJo3by4/Pz8tWbJEkydPdmpfpEgRBQQE6P3331fPnj3l6+t709e22+2y2+3Z2BsAAAAAeU2uzcCVL19e7u7u2rZtm2PZ1atXtWvXLlWqVClV+9DQUO3cudNp2Y4dO1K1O378uH777TenNi4uLqpYsaKKFSumgIAA/fLLLwoODna6lS1bVtLfu0UGBgZq2LBhqlWrlkJCQnTs2LFUr+Pp6anVq1fLw8NDzZs314ULF7L8XgAAAABARuTaDJy3t7eeffZZDRw4UAULFlSZMmU0ceJEXbp0SU899ZS+//57p/b9+/dX/fr1NWnSJLVt21Zr167V559/nmq9Hh4e6tatmyZNmqTz58+rf//+6tixo4oXLy5JioqKUv/+/eXn56cWLVooISFB3377rc6ePasXX3xRISEhOn78uJYsWaLatWvr008/1UcffZRuHz799FM9/PDDevjhh/X555/Lx8cn+98sAAAAAFAun4VywoQJ+s9//qMuXbrovvvu0+HDh7V27VoVKFAgVdv7779f8+bN0/Tp01W9enWtW7dOw4cPT9UuODhY7du3V8uWLdWsWTNVq1bN6TIBvXr10vz587VgwQJVrVpV4eHhWrhwoWMGrk2bNnrhhRfUr18/1ahRQ19//bVGjBiRbh98fHy0Zs0aGWPUqlUrXbx4MRveGQAAAABIzWbuoguXjRo1SitXrtTevXtzu5RbOn/+/N9noxywTC52r9wuBwAAAMgzYia0yu0SnKRkg7i4uFueWyNXZ+AAAAAAABlHgAMAAAAAi7irAtyoUaMssfskAAAAAGTFXRXgAAAAAOBuRoADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAW4ZbbBeR1P0Y1l6+vb26XAQAAAMACmIEDAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAW4ZbbBeR1VV5ZKxe7V26XAQAAAAuKmdAqt0vAHcYMHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCXDqSk5M1ceJEBQcHy263q0yZMho7dqxiYmJks9m0ZMkShYWFycPDQ1WqVNHWrVtzu2QAAAAAdzm33C7g32ro0KGaN2+epk6dqgYNGig2NlYHDhxwPD5w4EBNmzZNlSpV0pQpUxQREaGjR4+qUKFCaa4vISFBCQkJjvvnz5/P8T4AAAAAuLswA5eGCxcuaPr06Zo4caK6deum8uXLq0GDBurVq5ejTb9+/fSf//xHoaGhmjNnjvz8/PTWW2+lu87x48fLz8/PcStduvSd6AoAAACAuwgBLg3R0dFKSEhQkyZN0m1Tr149x89ubm6qVauWoqOj020/dOhQxcXFOW4nTpzI1poBAAAA3P3YhTINnp6e2b5Ou90uu92e7esFAAAAkHcwA5eGkJAQeXp6auPGjem22bFjh+Pna9euaffu3QoNDb0T5QEAAADIo5iBS4OHh4cGDx6sQYMGyd3dXfXr19cff/yh/fv3O3arnDVrlkJCQhQaGqqpU6fq7Nmz6tmzZy5XDgAAAOBuRoBLx4gRI+Tm5qaRI0fqt99+U4kSJdSnTx/H4xMmTNCECRO0d+9eBQcH6+OPP1bhwoVzsWIAAAAAdzsCXDpcXFw0bNgwDRs2zGl5TEyMJCk0NFQ7d+7MhcoAAAAA5FUcAwcAAAAAFkGAAwAAAACLYBfKTAoKCpIxJrfLAAAAAJAHMQMHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABbhltsF5HU/RjWXr69vbpcBAAAAwAKYgQMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAi3DL7QLyuiqvrJWL3Su3ywAAAMjTYia0yu0SgAxhBg4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARWQ5wL377ruqX7++AgICdOzYMUnStGnTtGrVqmwrDgAAAADwjywFuDlz5ujFF19Uy5Ytde7cOSUlJUmS/P39NW3atOysDwAAAADw/2UpwM2YMUPz5s3TsGHD5Orq6lheq1Yt7du3L9uKAwAAAAD8I0sB7ujRo7r33ntTLbfb7bp48eJtFwUAAAAASC1LAa5s2bLau3dvquWff/65QkNDb7cmAAAAAEAa3LLypBdffFF9+/bVlStXZIzRN998o/fff1/jx4/X/Pnzs7tGAAAAAICyGOB69eolT09PDR8+XJcuXVKnTp0UEBCg6dOn6/HHH8/uGgEAAAAAykKAu3btmhYvXqzmzZurc+fOunTpkuLj41W0aNGcqA8AAAAA8P9l+hg4Nzc39enTR1euXJEkeXl5Ed4AAAAA4A7I0klM6tSpoz179mR3LQAAAACAm8jSMXDPPfecXnrpJf3666+qWbOmvL29nR6vVq1athQHAAAAAPhHlgJcyolK+vfv71hms9lkjJHNZlNSUlL2VAcAAAAAcMhSgDt69Gh21wEAAAAAuIUsBbjAwMDsrgMAAAAAcAtZCnDvvPPOTR/v2rVrlooBAAAAAKQvSwHu+eefd7p/9epVXbp0Se7u7vLy8iLAAQAAAEAOyNJlBM6ePet0i4+P18GDB9WgQQO9//772V0jAAAAAEBZDHBpCQkJ0YQJE1LNzt2OLVu2yGaz6dy5c7e1nqCgIE2bNi1bapKkxo0ba8CAAdm2PgAAAADIiGwLcJLk5uam3377LcvPJxgBAAAAQPqydAzcxx9/7HTfGKPY2FjNnDlT9evXz5bCAAAAAADOsjQD98gjjzjd2rdvr1GjRqlatWp6++23s1RI9+7dtXXrVk2fPl02m002m00xMTGSpN27d6tWrVry8vJSWFiYDh486HjekSNH1LZtWxUrVkw+Pj6qXbu2NmzYcNPXmjJliqpWrSpvb2+VLl1azz33nOLj453abNu2TY0bN5aXl5cKFCig5s2b6+zZs47Hk5OTNWjQIBUsWFDFixfXqFGjstRvAAAAAMioLAW45ORkp1tSUpJ+//13LV68WCVKlMhSIdOnT1e9evXUu3dvxcbGKjY2VqVLl5YkDRs2TJMnT9a3334rNzc39ezZ0/G8+Ph4tWzZUhs3btSePXvUokULRURE6Pjx4+m+louLi15//XXt379fixYt0qZNmzRo0CDH43v37lWTJk1UqVIlbd++XV999ZUiIiKUlJTkaLNo0SJ5e3tr586dmjhxokaPHq3169en+5oJCQk6f/680w0AAAAAMiNLAW706NG6dOlSquWXL1/W6NGjs1SIn5+f4zIExYsXV/HixeXq6ipJGjt2rMLDw1WpUiUNGTJEX3/9ta5cuSJJql69up555hlVqVJFISEhGjNmjMqXL59qN8/rDRgwQA888ICCgoL04IMP6tVXX9WyZcscj0+cOFG1atXS7NmzVb16dVWuXFn9+vVT4cKFHW2qVaumV155RSEhIeratatq1aqljRs3pvua48ePl5+fn+OWEk4BAAAAIKOyFOCioqJS7XIoSZcuXVJUVNRtF3WjatWqOX5OmeE7ffq0pL9n4CIjIxUaGip/f3/5+PgoOjr6pjNwGzZsUJMmTVSyZEnlz59fXbp00ZkzZxyhNGUGLqM1pdSVUlNahg4dqri4OMftxIkTN+80AAAAANwgSwHOGCObzZZq+ffff6+CBQvedlE3ypcvn+PnlNdNTk6WJEVGRuqjjz7SuHHj9OWXX2rv3r2qWrWqEhMT01xXTEyMWrdurWrVqmnFihXavXu3Zs2aJUmO53h6emaqppS6UmpKi91ul6+vr9MNAAAAADIjU2ehLFCggOMEIxUqVHAKcUlJSYqPj1efPn2yXIy7u7vTcWYZsW3bNnXv3l3t2rWT9PeMXMrJT9Kye/duJScna/LkyXJx+Tu/Xr/7pPT37NrGjRtzZDYRAAAAALIqUwFu2rRpMsaoZ8+eioqKkp+fn+Mxd3d3BQUFqV69elkuJigoSDt37lRMTIx8fHxuOqOVIiQkRB9++KEiIiJks9k0YsSImz4vODhYV69e1YwZMxQREaFt27bpjTfecGozdOhQVa1aVc8995z69Okjd3d3bd68WY8++qjTcXAAAAAAcCdlKsB169ZNklS2bFmFhYWl2o3wdkVGRqpbt26qVKmSLl++rAULFtzyOVOmTFHPnj0VFhamwoULa/DgwTc9w2P16tU1ZcoUvfbaaxo6dKgaNWqk8ePHq2vXro42FSpU0Lp16/Tyyy+rTp068vT0VN26dfXEE09kSz8BAAAAICtsxhhzOyu4cuVKquPNOL7r1s6fP//32SgHLJOL3Su3ywEAAMjTYia0yu0SkIelZIO4uLhbZqksncTk0qVL6tevn4oWLSpvb28VKFDA6QYAAAAAyH5ZCnADBw7Upk2bNGfOHNntds2fP19RUVEKCAjQO++8k901AgAAAACUyWPgUnzyySd655131LhxY/Xo0UMNGzZUcHCwAgMD9d5776lz587ZXScAAAAA5HlZmoH766+/VK5cOUl/H+/2119/SZIaNGigL774IvuqAwAAAAA4ZCnAlStXTkePHpUk3XPPPY7rqH3yySfy9/fPtuIAAAAAAP/IUoDr0aOHvv/+e0nSkCFDNGvWLHl4eOiFF17QwIEDs7VAAAAAAMDfsnQM3AsvvOD4uWnTpjpw4IB2796t4OBgVatWLduKAwAAAAD8I0sB7npXrlxRYGCgAgMDs6MeAAAAAEA6srQLZVJSksaMGaOSJUvKx8dHv/zyiyRpxIgReuutt7K1QAAAAADA37IU4MaOHauFCxdq4sSJcnd3dyyvUqWK5s+fn23FAQAAAAD+kaUA98477+jNN99U586d5erq6lhevXp1HThwINuKAwAAAAD8I0sB7uTJkwoODk61PDk5WVevXr3togAAAAAAqWUpwFWqVElffvllquUffPCB7r333tsuCgAAAACQWpbOQjly5Eh169ZNJ0+eVHJysj788EMdPHhQ77zzjlavXp3dNQIAAAAAlMkZuF9++UXGGLVt21affPKJNmzYIG9vb40cOVLR0dH65JNP9NBDD+VUrQAAAACQp2VqBi4kJESxsbEqWrSoGjZsqIIFC2rfvn0qVqxYTtUHAAAAAPj/MjUDZ4xxur9mzRpdvHgxWwsCAAAAAKQtSycxSXFjoAMAAAAA5JxMBTibzSabzZZqGQAAAAAg52XqGDhjjLp37y673S5JunLlivr06SNvb2+ndh9++GH2VQgAAAAAkJTJANetWzen+08++WS2FgMAAAAASF+mAtyCBQtyqg4AAAAAwC3c1klMAAAAAAB3DgEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIjJ1GQFkvx+jmsvX1ze3ywAAAABgAczAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAi3DL7QLyuiqvrJWL3Su3ywAAALjrxExoldslANmOGTgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBLh0JCcna+LEiQoODpbdbleZMmU0duxYSdLgwYNVoUIFeXl5qVy5choxYoSuXr2ayxUDAAAAuNu55XYB/1ZDhw7VvHnzNHXqVDVo0ECxsbE6cOCAJCl//vxauHChAgICtG/fPvXu3Vv58+fXoEGD0l1fQkKCEhISHPfPnz+f430AAAAAcHexGWNMbhfxb3PhwgUVKVJEM2fOVK9evW7ZftKkSVqyZIm+/fbbdNuMGjVKUVFRqZaXHrBMLnav26oXAAAAqcVMaJXbJQAZcv78efn5+SkuLk6+vr43bcsulGmIjo5WQkKCmjRpkubjS5cuVf369VW8eHH5+Pho+PDhOn78+E3XOXToUMXFxTluJ06cyInSAQAAANzFCHBp8PT0TPex7du3q3PnzmrZsqVWr16tPXv2aNiwYUpMTLzpOu12u3x9fZ1uAAAAAJAZBLg0hISEyNPTUxs3bkz12Ndff63AwEANGzZMtWrVUkhIiI4dO5YLVQIAAADIaziJSRo8PDw0ePBgDRo0SO7u7qpfv77++OMP7d+/XyEhITp+/LiWLFmi2rVr69NPP9VHH32U2yUDAAAAyAOYgUvHiBEj9NJLL2nkyJEKDQ3VY489ptOnT6tNmzZ64YUX1K9fP9WoUUNff/21RowYkdvlAgAAAMgDOAtlLkk50wxnoQQAAMgZnIUSVsFZKAEAAADgLkSAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAItxyu4C87seo5vL19c3tMgAAAABYADNwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARbrldQF5X5ZW1crF75XYZAAAAtxQzoVVulwDkeczAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWESeD3BbtmyRzWbTuXPnbms9QUFBmjZtWrbUBAAAAABpyXMBrnHjxhowYEBulwEAAAAAmZbnAhwAAAAAWFWeCnDdu3fX1q1bNX36dNlsNtlsNsXExEiSdu/erVq1asnLy0thYWE6ePCg43lHjhxR27ZtVaxYMfn4+Kh27drasGFDLvUCAAAAQF6VpwLc9OnTVa9ePfXu3VuxsbGKjY1V6dKlJUnDhg3T5MmT9e2338rNzU09e/Z0PC8+Pl4tW7bUxo0btWfPHrVo0UIRERE6fvx4hl87ISFB58+fd7oBAAAAQGbkqQDn5+cnd3d3eXl5qXjx4ipevLhcXV0lSWPHjlV4eLgqVaqkIUOG6Ouvv9aVK1ckSdWrV9czzzyjKlWqKCQkRGPGjFH58uX18ccfZ/i1x48fLz8/P8ctJTgCAAAAQEblqQB3M9WqVXP8XKJECUnS6dOnJf09AxcZGanQ0FD5+/vLx8dH0dHRmZqBGzp0qOLi4hy3EydOZG8HAAAAANz13HK7gH+LfPnyOX622WySpOTkZElSZGSk1q9fr0mTJik4OFienp7q0KGDEhMTM7x+u90uu92evUUDAAAAyFPyXIBzd3dXUlJSpp6zbds2de/eXe3atZP094xcyslPAAAAAOBOyXO7UAYFBWnnzp2KiYnRn3/+6Zhlu5mQkBB9+OGH2rt3r77//nt16tQpQ88DAAAAgOyU5wJcZGSkXF1dValSJRUpUiRDx7FNmTJFBQoUUFhYmCIiItS8eXPdd999d6BaAAAAAPiHzRhjcruIvOj8+fN/n41ywDK52L1yuxwAAIBbipnQKrdLAO5KKdkgLi5Ovr6+N22b52bgAAAAAMCqCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFiEW24XkNf9GNVcvr6+uV0GAAAAAAtgBg4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAIsgwAEAAACARRDgAAAAAMAiCHAAAAAAYBEEOAAAAACwCAIcAAAAAFgEAQ4AAAAALIIABwAAAAAWQYADAAAAAItwy+0C8ipjjCTp/PnzuVwJAAAAgNyUkglSMsLNEOByyZkzZyRJpUuXzuVKAAAAAPwbXLhwQX5+fjdtQ4DLJQULFpQkHT9+/JaDhNx3/vx5lS5dWidOnJCvr29ul4MMYMyshfGyHsbMehgza2G8rOd2xswYowsXLiggIOCWbQlwucTF5e/DD/38/PhSWoivry/jZTGMmbUwXtbDmFkPY2YtjJf1ZHXMMjqpw0lMAAAAAMAiCHAAAAAAYBEEuFxit9v1yiuvyG6353YpyADGy3oYM2thvKyHMbMexsxaGC/ruVNjZjMZOVclAAAAACDXMQMHAAAAABZBgAMAAAAAiyDAAQAAAIBFEOAAAAAAwCIIcNlk1qxZCgoKkoeHh+rWratvvvnmpu2XL1+ue+65Rx4eHqpatao+++wzp8eNMRo5cqRKlCghT09PNW3aVIcOHcrJLuQ52TlmV69e1eDBg1W1alV5e3srICBAXbt21W+//ZbT3cgzsvs7dr0+ffrIZrNp2rRp2Vx13pYTYxYdHa02bdrIz89P3t7eql27to4fP55TXchzsnvM4uPj1a9fP5UqVUqenp6qVKmS3njjjZzsQp6SmfHav3+//vOf/ygoKOim27vMfgaQOdk9ZuPHj1ft2rWVP39+FS1aVI888ogOHjyYgz3IW3LiO5ZiwoQJstlsGjBgQOYLM7htS5YsMe7u7ubtt982+/fvN7179zb+/v7m1KlTabbftm2bcXV1NRMnTjQ//fSTGT58uMmXL5/Zt2+fo82ECROMn5+fWblypfn+++9NmzZtTNmyZc3ly5fvVLfuatk9ZufOnTNNmzY1S5cuNQcOHDDbt283derUMTVr1ryT3bpr5cR3LMWHH35oqlevbgICAszUqVNzuCd5R06M2eHDh03BggXNwIEDzXfffWcOHz5sVq1ale46kTk5MWa9e/c25cuXN5s3bzZHjx41c+fONa6urmbVqlV3qlt3rcyO1zfffGMiIyPN+++/b4oXL57m9i6z60Tm5MSYNW/e3CxYsMD8+OOPZu/evaZly5amTJkyJj4+Pod7c/fLifG6vm1QUJCpVq2aef755zNdGwEuG9SpU8f07dvXcT8pKckEBASY8ePHp9m+Y8eOplWrVk7L6tata5555hljjDHJycmmePHi5n//+5/j8XPnzhm73W7ef//9HOhB3pPdY5aWb775xkgyx44dy56i87CcGq9ff/3VlCxZ0vz4448mMDCQAJeNcmLMHnvsMfPkk0/mTMHIkTGrXLmyGT16tFOb++67zwwbNiwbK8+bMjte10tve3c768St5cSY3ej06dNGktm6devtlAqTc+N14cIFExISYtavX2/Cw8OzFODYhfI2JSYmavfu3WratKljmYuLi5o2bart27en+Zzt27c7tZek5s2bO9ofPXpUv//+u1MbPz8/1a1bN911IuNyYszSEhcXJ5vNJn9//2ypO6/KqfFKTk5Wly5dNHDgQFWuXDlnis+jcmLMkpOT9emnn6pChQpq3ry5ihYtqrp162rlypU51o+8JKe+Z2FhYfr444918uRJGWO0efNm/fzzz2rWrFnOdCSPyMp45cY68Y879f7GxcVJkgoWLJht68yLcnK8+vbtq1atWqXafmYGAe42/fnnn0pKSlKxYsWclhcrVky///57ms/5/fffb9o+5d/MrBMZlxNjdqMrV65o8ODBeuKJJ+Tr65s9hedROTVer732mtzc3NS/f//sLzqPy4kxO336tOLj4zVhwgS1aNFC69atU7t27dS+fXtt3bo1ZzqSh+TU92zGjBmqVKmSSpUqJXd3d7Vo0UKzZs1So0aNsr8TeUhWxis31ol/3In3Nzk5WQMGDFD9+vVVpUqVbFlnXpVT47VkyRJ99913Gj9+/G3V53ZbzwaQytWrV9WxY0cZYzRnzpzcLgdp2L17t6ZPn67vvvtONpstt8tBBiQnJ0uS2rZtqxdeeEGSVKNGDX399dd64403FB4enpvlIR0zZszQjh079PHHHyswMFBffPGF+vbtq4CAgNv66zOA1Pr27asff/xRX331VW6XgjScOHFCzz//vNavXy8PD4/bWhczcLepcOHCcnV11alTp5yWnzp1SsWLF0/zOcWLF79p+5R/M7NOZFxOjFmKlPB27NgxrV+/ntm3bJAT4/Xll1/q9OnTKlOmjNzc3OTm5qZjx47ppZdeUlBQUI70Iy/JiTErXLiw3NzcVKlSJac2oaGhnIUyG+TEmF2+fFkvv/yypkyZooiICFWrVk39+vXTY489pkmTJuVMR/KIrIxXbqwT/8jp97dfv35avXq1Nm/erFKlSt32+vK6nBiv3bt36/Tp07rvvvscv3ts3bpVr7/+utzc3JSUlJThdRHgbpO7u7tq1qypjRs3OpYlJydr48aNqlevXprPqVevnlN7SVq/fr2jfdmyZVW8eHGnNufPn9fOnTvTXScyLifGTPonvB06dEgbNmxQoUKFcqYDeUxOjFeXLl30ww8/aO/evY5bQECABg4cqLVr1+ZcZ/KInBgzd3d31a5dO9XpsX/++WcFBgZmcw/ynpwYs6tXr+rq1atycXH+VcPV1dUxo4qsycp45cY68Y+cen+NMerXr58++ugjbdq0SWXLls2OcvO8nBivJk2aaN++fU6/e9SqVUudO3fW3r175erqmvGVZfq0J0hlyZIlxm63m4ULF5qffvrJPP3008bf39/8/vvvxhhjunTpYoYMGeJov23bNuPm5mYmTZpkoqOjzSuvvJLmZQT8/f3NqlWrzA8//GDatm3LZQSyUXaPWWJiomnTpo0pVaqU2bt3r4mNjXXcEhIScqWPd5Oc+I7diLNQZq+cGLMPP/zQ5MuXz7z55pvm0KFDZsaMGcbV1dV8+eWXd7x/d6OcGLPw8HBTuXJls3nzZvPLL7+YBQsWGA8PDzN79uw73r+7TWbHKyEhwezZs8fs2bPHlChRwkRGRpo9e/aYQ4cOZXiduD05MWbPPvus8fPzM1u2bHH63ePSpUt3vH93m5wYrxtl9SyUBLhsMmPGDFOmTBnj7u5u6tSpY3bs2OF4LDw83HTr1s2p/bJly0yFChWMu7u7qVy5svn000+dHk9OTjYjRowwxYoVM3a73TRp0sQcPHjwTnQlz8jOMTt69KiRlOZt8+bNd6hHd7fs/o7diACX/XJizN566y0THBxsPDw8TPXq1c3KlStzuht5SnaPWWxsrOnevbsJCAgwHh4epmLFimby5MkmOTn5TnTnrpeZ8Urv/6nw8PAMrxO3L7vHLL3fPRYsWHDnOnUXy4nv2PWyGuBsxhiTpXlAAAAAAMAdxTFwAAAAAGARBDgAAAAAsAgCHAAAAABYBAEOAAAAACyCAAcAAAAAFkGAAwAAAACLIMABAAAAgEUQ4AAAAADAIghwAAAAAGARBDgAwB3XvXt32Wy2VLfDhw9ny/oXLlwof3//bFlXVnXv3l2PPPJIrtZwMzExMbLZbNq7d29ulwIAyAS33C4AAJA3tWjRQgsWLHBaVqRIkVyqJn1Xr15Vvnz5cruMbJWYmJjbJQAAsogZOABArrDb7SpevLjTzdXVVZK0atUq3XffffLw8FC5cuUUFRWla9euOZ47ZcoUVa1aVd7e3ipdurSee+45xcfHS5K2bNmiHj16KC4uzjGzN2rUKEmSzWbTypUrnerw9/fXwoULJf0zK7V06VKFh4fLw8ND7733niRp/vz5Cg0NlYeHh+655x7Nnj07U/1t3Lix/vvf/2rAgAEqUKCAihUrpnnz5unixYvq0aOH8ufPr+DgYK1Zs8bxnC1btshms+nTTz9VtWrV5OHhofvvv18//vij07pXrFihypUry263KygoSJMnT3Z6PCgoSGPGjFHXrl3l6+urp59+WmXLlpUk3XvvvbLZbGrcuLEkadeuXXrooYdUuHBh+fn5KTw8XN99953T+mw2m+bPn6927drJy8tLISEh+vjjj53a7N+/X61bt5avr6/y58+vhg0b6siRI47Hb/f9BIC8igAHAPhX+fLLL9W1a1c9//zz+umnnzR37lwtXLhQY8eOdbRxcXHR66+/rv3792vRokXatGmTBg0aJEkKCwvTtGnT5Ovrq9jYWMXGxioyMjJTNQwZMkTPP/+8oqOj1bx5c7333nsaOXKkxo4dq+joaI0bN04jRozQokWLMrXeRYsWqXDhwvrmm2/03//+V88++6weffRRhYWF6bvvvlOzZs3UpUsXXbp0yel5AwcO1OTJk7Vr1y4VKVJEERERunr1qiRp9+7d6tixox5//HHt27dPo0aN0ogRIxyhNMWkSZNUvXp17dmzRyNGjNA333wjSdqwYYNiY2P14YcfSpIuXLigbt266auvvtKOHTsUEhKili1b6sKFC07ri4qKUseOHfXDDz+oZcuW6ty5s/766y9J0smTJ9WoUSPZ7XZt2rRJu3fvVs+ePR0hPLveTwDIkwwAAHdYt27djKurq/H29nbcOnToYIwxpkmTJmbcuHFO7d99911TokSJdNe3fPlyU6hQIcf9BQsWGD8/v1TtJJmPPvrIaZmfn59ZsGCBMcaYo0ePGklm2rRpTm3Kly9vFi9e7LRszJgxpl69ejftY9u2bR33w8PDTYMGDRz3r127Zry9vU2XLl0cy2JjY40ks337dmOMMZs3bzaSzJIlSxxtzpw5Yzw9Pc3SpUuNMcZ06tTJPPTQQ06vPXDgQFOpUiXH/cDAQPPII484tUnp6549e9LtgzHGJCUlmfz585tPPvnEsUySGT58uON+fHy8kWTWrFljjDFm6NChpmzZsiYxMTHNdWbl/QQA/I1j4AAAueKBBx7QnDlzHPe9vb0lSd9//722bdvmNOOWlJSkK1eu6NKlS/Ly8tKGDRs0fvx4HThwQOfPn9e1a9ecHr9dtWrVcvx88eJFHTlyRE899ZR69+7tWH7t2jX5+fllar3VqlVz/Ozq6qpChQqpatWqjmXFihWTJJ0+fdrpefXq1XP8XLBgQVWsWFHR0dGSpOjoaLVt29apff369TVt2jQlJSU5dku9vk83c+rUKQ0fPlxbtmzR6dOnlZSUpEuXLun48ePp9sXb21u+vr6Ouvfu3auGDRumeexgdr6fAJAXEeAAALnC29tbwcHBqZbHx8crKipK7du3T/WYh4eHYmJi1Lp1az377LMaO3asChYsqK+++kpPPfWUEhMTbxrgbDabjDFOy1J2RbyxtuvrkaR58+apbt26Tu1SwlFG3RhobDab0zKbzSZJSk5OztR6M+L6Pt1Mt27ddObMGU2fPl2BgYGy2+2qV69eqhOfpNWXlLo9PT3TXX92vp8AkBcR4AAA/yr33XefDh48mGa4k/4+5is5OVmTJ0+Wi8vfh3IvW7bMqY27u7uSkpJSPbdIkSKKjY113D906FCq481uVKxYMQUEBOiXX35R586dM9udbLFjxw6VKVNGknT27Fn9/PPPCg0NlSSFhoZq27ZtTu23bdumChUq3DQQubu7S1Kq92nbtm2aPXu2WrZsKUk6ceKE/vzzz0zVW61aNS1atCjNM3j+G95PALAyAhwA4F9l5MiRat26tcqUKaMOHTrIxcVF33//vX788Ue9+uqrCg4O1tWrVzVjxgxFRERo27ZteuONN5zWERQUpPj4eG3cuFHVq1eXl5eXvLy89OCDD2rmzJmqV6+ekpKSNHjw4AxdIiAqKkr9+/eXn5+fWrRooYSEBH377bc6e/asXnzxxZx6KxxGjx6tQoUKqVixYho2bJgKFy7suMbcSy+9pNq1a2vMmDF67LHHtH37ds2cOfOWZ3UsWrSoPD099fnnn6tUqVLy8PCQn5+fQkJC9O6776pWrVo6f/68Bg4ceNMZtbT069dPM2bM0OOPP66hQ4fKz89PO3bsUJ06dVSxYsVcfz8BwMo4CyUA4F+lefPmWr16tdatW6fatWvr/vvv19SpUxUYGChJql69uqZMmaLXXntNVapU0Xvvvafx48c7rSMsLEx9+vTRY489piJFimjixImSpMmTJ6t06dJq2LChOnXqpMjIyAwdM9erVy/Nnz9fCxYsUNWqVRUeHq6FCxc6TsWf0yZMmKDnn39eNWvW1O+//65PPvnEMYN23333admyZVqyZImqVKmikSNHavTo0erevftN1+nm5qbXX39dc+fOVUBAgOM4urfeektnz57Vfffdpy5duqh///4qWrRopuotVKiQNm3apPj4eIWHh6tmzZqaN2+eIyzn9vsJAFZmMzceDAAAAP4VtmzZogceeEBnz56Vv79/bpcDAPgXYAYOAAAAACyCAAcAAAAAFsEulAAAAABgEczAAQAAAIBFEOAAAAAAwCIIcAAAAABgEQQ4AAAAALAIAhwAAAAAWAQBDgAAAAAsggAHAAAAABZBgAMAAAAAi/h/2XLPAAGaSW0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = df.columns.to_list()\n",
    "top5_feature_names = [feature_names[i] for i in top5]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(top5)), feature_importance[top5], align='center')\n",
    "plt.yticks(range(len(top5)), top5_feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 5 Most Important Features for Heart Disease Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d0af956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth' : [3, 5, 10, None],\n",
    "    'n_estimators' : [100, 200, 300],\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf' : [1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5df6d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.884 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.738 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.738 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.905 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.884 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.738 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.905 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.860 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   3.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.791 total time=   0.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.881 total time=   1.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.881 total time=   0.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.810 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.860 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.786 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.786 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.762 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.767 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.860 total time=   0.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.881 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.814 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.881 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.762 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.881 total time=   0.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.881 total time=   0.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.738 total time=   0.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.884 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.884 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.905 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.905 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.738 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.884 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.860 total time=   0.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.860 total time=   0.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.810 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.810 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.810 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.810 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.884 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=1, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=2, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.905 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.884 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.884 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.905 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, min_samples_leaf=4, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.791 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=1, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=200;, score=0.881 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.791 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=100;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.744 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.791 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.762 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.860 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, min_samples_leaf=4, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.762 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.814 total time=   0.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.762 total time=   0.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=1, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=200;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.786 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=2, n_estimators=300;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.860 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=200;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.814 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.810 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=3, n_estimators=300;, score=0.857 total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.814 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=100;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.814 total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.857 total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.786 total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=200;, score=0.810 total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.810 total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, min_samples_leaf=4, n_estimators=300;, score=0.881 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 10, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 10, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [3, 5, 10, None],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), param_grid=params, cv=5, verbose=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca9c2a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "923dc0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c2ed8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9560439560439561\n",
      "0.9811320754716981\n",
      "0.9454545454545454\n",
      "0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred_test, y_pred))\n",
    "print(precision_score(y_pred_test, y_pred))\n",
    "print(recall_score(y_pred_test, y_pred))\n",
    "print(f1_score(y_pred_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7253bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfromance comparision\n",
    "# New random forest classifier trained using gridsearchcv (tuned model) is performing better in all performance metrics.\n",
    "# So tuned model is better then default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "863adc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x210ec9b7f90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "feature1_index = top5[0]\n",
    "feature2_index = top5[1]\n",
    "\n",
    "plt.scatter(X.iloc[:, feature1_index], y)\n",
    "plt.scatter(X.iloc[:, feature2_index], y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
