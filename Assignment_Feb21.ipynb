{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ab3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\n",
    "\n",
    "# Web scraping is a method which is used to extract data from a website using some program or software.\n",
    "\n",
    "# Web scraping is used to automate the process of extracting data from a website rather than manual copy and paste.\n",
    "\n",
    "# Web scraping is used in different areas like price comparison, data mining, content aggregation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b15200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "\n",
    "# Different methods which are used for Web Scraping are:\n",
    "\n",
    "# HTML Parsing: This involves parsing of the HTML code and extracting the required data.\n",
    "# Web Scraping Libraries: Web scraping using different libraries for python like requests, beautiful soup, scrapy, etc.\n",
    "# Regular Expressions: It can be used to extract data from the text content of a web page, such as email addresses or phone numbers.\n",
    "# APIs: Some website provides an API through which we can access data directly.\n",
    "# Headless Browsers: Headless browsers can be used to simulate a web browser and extract data from web pages that require user interaction, such as clicking buttons or filling out forms.\n",
    "# Data Extraction Services: There are also third-party services for web scraping, such as import.io and ParseHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9396cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\n",
    "\n",
    "# Beautiful Soup is a python library which is used for web scraping.\n",
    "# It can be used to parse HTML and XML Documents and extract information from them.\n",
    "\n",
    "# It can be used to extract data from websites that are built with dynamic content or are difficult to scrape with other methods.\n",
    "# Beautiful Soup can also handle poorly formed HTML and XML documents, which can be a problem with other parsing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24f0a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.\n",
    "\n",
    "# In this project, we have used flask because it is more flexible, lightweight and easy to use.\n",
    "# Flask can be easily integrated with other python libraries like beautiful soup, pymongo, requests, etc.\n",
    "# Flask can be easily deployed to a variety of web servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6781946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\n",
    "\n",
    "# AWS services which are used in the project are CodePipeline and Elastic Beanstalk.\n",
    "\n",
    "# AWS CodePipeline is a continuous delivery service that automates the software release process.\n",
    "# In project, it is used to carries code from the source provider i.e. github to Elastic Beanstalk.\n",
    "\n",
    "# AWS Elastic Beanstalk is a platform as a service (PaaS) that allows developers to deploy and manage web applications without worrying about the underlying infrastructure.\n",
    "# It is used to deploy our project over internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800cc63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
