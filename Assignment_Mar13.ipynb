{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb8170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\n",
    "\n",
    "# Assumptions of ANOVA:\n",
    "\n",
    "# Normality of Sampling Distribution of means.\n",
    "# Absense of Outliers.\n",
    "# Homegenety of Variance.\n",
    "# Samples are independent and random.\n",
    "\n",
    "# Violation\n",
    "\n",
    "# Violations of independence:\n",
    "# Correlated observations within groups or dependencies between measurements over time can lead to biased results.\n",
    "\n",
    "# Violations of normality:\n",
    "# Non-normal distributions of the dependent variable within groups can affect the accuracy of p-values and confidence intervals.\n",
    "\n",
    "# Violations of homogeneity of variances:\n",
    "# Unequal variances between groups can result in incorrect conclusions about group differences.\n",
    "\n",
    "# Violations of linearity:\n",
    "# Nonlinear relationships between the dependent variable and independent variable(s) can lead to misleading interpretations of group differences.\n",
    "\n",
    "# Violations of random sampling:\n",
    "# Non-random sampling methods can compromise the generalizability of the results, introducing bias in the conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d005c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "\n",
    "# One Way ANOVA:\n",
    "# When there is one factor with atleast 2 levels.\n",
    "# These levels are independent.\n",
    "\n",
    "# Repeated Measures ANOVA:\n",
    "# When there is one factor with atleast 2 levels.\n",
    "# These levels are dependent.\n",
    "\n",
    "# Factorial ANOVA:\n",
    "# When there are two or more factors each with atleast 2 levels.\n",
    "# These levels can be either dependent or independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d884a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\n",
    "\n",
    "# Partitioning of variance in ANOVA:\n",
    "# The partitioning of variance in ANOVA involves breaking down the total variation observed in the data into different components associated with specific factors or sources.\n",
    "\n",
    "# Importance of partitioning of variance in ANOVA:\n",
    "# This concept is important because it allows researchers to understand the relative contributions of various factors to the observed differences between groups.\n",
    "# By quantifying the amount of variance explained by each factor, ANOVA helps determine the significance of group differences and assess the impact of independent variables on the dependent variable.\n",
    "# Understanding the partitioning of variance aids in making informed interpretations, identifying significant factors, and guiding further analyses.\n",
    "# It enhances the validity and interpretability of the results, facilitating a deeper understanding of the relationships between variables and providing a foundation for subsequent statistical investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef7e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 163.33333333333331\n",
      "Explained sum of squares (SSE): 43.33333333333333\n",
      "Residual sum of squares (SSR): 119.99999999999999\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "group1 = [5, 7, 9, 11, 13]\n",
    "group2 = [2, 4, 6, 8, 10]\n",
    "group3 = [1, 3, 5, 7, 9]\n",
    "\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "overall_mean = np.mean(data)\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "sse = np.sum((group_means - overall_mean)**2) * len(group1)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total sum of squares (SST):\", sst)\n",
    "print(\"Explained sum of squares (SSE):\", sse)\n",
    "print(\"Residual sum of squares (SSR):\", ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45317340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect Group 1: 208.41674207731316\n",
      "Main Effect Group 2: 126.57179429259548\n",
      "Interaction Effect: 2.2574113767654446e-27\n"
     ]
    }
   ],
   "source": [
    "#5.\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = pd.DataFrame({'Group1': [10, 12, 14, 16, 18],\n",
    "                     'Group2': [5, 10, 15, 20, 25],\n",
    "                     'Response': [25, 35, 45, 55, 65]})\n",
    "\n",
    "model = ols('Response ~ Group1 + Group2 + Group1:Group2', data=data).fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "main_effect_group1 = anova_table['sum_sq']['Group1']\n",
    "main_effect_group2 = anova_table['sum_sq']['Group2']\n",
    "interaction_effect = anova_table['sum_sq']['Group1:Group2']\n",
    "\n",
    "print(\"Main Effect Group 1:\", main_effect_group1)\n",
    "print(\"Main Effect Group 2:\", main_effect_group2)\n",
    "print(\"Interaction Effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "159d10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.\n",
    "\n",
    "# Based on the results of the one-way ANOVA, with an F-statistic of 5.23 and a p-value of 0.02.\n",
    "# We can conclude that there are statistically significant differences between the groups being compared.\n",
    "# The F-statistic indicates that the variability between the groups is greater than the variability within the groups.\n",
    "# The low p-value suggests that the observed differences are unlikely to occur by chance alone.\n",
    "# Therefore, we reject the null hypothesis of no differences between the groups and accept the alternative hypothesis that there are indeed significant differences.\n",
    "# Further analysis or post-hoc tests may be conducted to determine which specific groups are significantly different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "930ae0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.\n",
    "\n",
    "# Handling missing data in a repeated measures ANOVA requires careful consideration.\n",
    "# Complete Case Analysis (CCA) excludes cases with missing data, potentially leading to biased results.\n",
    "# Mean substitution/imputation can distort relationships and underestimate variability.\n",
    "# Multiple imputation captures uncertainty but is computationally intensive.\n",
    "# The choice of method can impact the validity and reliability of the results.\n",
    "# Inappropriate handling of missing data can introduce bias, reduce statistical power, and affect conclusions.\n",
    "# It is important to consider the missing data mechanism and choose appropriate techniques, such as multiple imputation or sensitivity analyses, to account for missingness and minimize potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc05809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.\n",
    "\n",
    "# Some common post-hoc tests used after ANOVA include Tukey's Honestly Significant Difference (HSD), Bonferroni correction, Dunnett's test, and Scheffé's test.\n",
    "\n",
    "# Tukey's HSD is commonly used to determine which specific groups differ significantly from each other. \n",
    "# It is appropriate when conducting multiple pairwise comparisons.\n",
    "# Bonferroni correction is a conservative approach that adjusts the significance level to control for multiple comparisons.\n",
    "# Dunnett's test is used when comparing multiple groups to a control group.\n",
    "# Scheffé's test is more conservative but suitable for situations where all possible comparisons need to be made.\n",
    "\n",
    "# For example, in a study comparing the effectiveness of three different treatments for a medical condition.\n",
    "# A post-hoc test like Tukey's HSD could be used to identify which specific treatment groups show statistically significant differences in outcomes after controlling for Type I error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5da4cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 389.7356865723879\n",
      "p-value: 7.7913363221494195e-59\n"
     ]
    }
   ],
   "source": [
    "#9.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "diet_A = [2.3, 1.9, 3.2, 2.7, 2.5, 1.8, 3.1, 2.4, 2.9, 2.2, 2.6, 2.1, 2.8, 2.4, 1.7, 2.0, 1.9, 2.2, 3.0, 2.5,\n",
    "          2.4, 2.1, 2.6, 2.3, 2.8, 2.0, 1.9, 2.7, 2.3, 2.5, 2.2, 2.1, 2.6, 2.4, 1.8, 2.9, 3.1, 2.5, 2.3, 2.7,\n",
    "          2.0, 2.8, 2.4, 1.7, 2.6, 2.2, 2.1, 2.5, 2.3, 2.9]\n",
    "\n",
    "diet_B = [3.5, 4.1, 3.9, 3.2, 4.2, 3.8, 4.0, 3.6, 3.4, 3.7, 4.1, 3.9, 3.6, 3.3, 4.0, 3.7, 4.2, 3.5, 3.8, 3.2,\n",
    "          3.9, 3.6, 4.1, 3.3, 4.0, 3.7, 3.5, 4.2, 3.8, 3.6, 3.4, 3.7, 4.1, 3.9, 3.6, 3.3, 4.0, 3.7, 4.2, 3.5,\n",
    "          3.8, 3.2, 3.9, 3.6, 4.1, 3.3, 4.0, 3.7, 3.5]\n",
    "\n",
    "diet_C = [1.9, 2.1, 1.7, 2.4, 1.5, 2.0, 1.8, 2.2, 2.3, 1.6, 2.0, 1.7, 2.1, 1.9, 2.4, 1.5, 2.3, 1.8, 2.2, 2.1,\n",
    "          1.6, 2.0, 1.7, 2.3, 1.9, 2.4, 1.5, 2.2, 2.0, 1.8, 2.1, 1.7, 2.3, 1.9, 2.4, 1.5, 2.1, 2.0, 1.8, 2.2,\n",
    "          2.3, 1.6, 2.0, 1.7, 2.1, 1.9, 2.4, 1.5]\n",
    "\n",
    "weight_loss_data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "group_labels = ['A'] * len(diet_A) + ['B'] * len(diet_B) + ['C'] * len(diet_C)\n",
    "\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a389de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic Program: 0.03166869671132745\n",
      "p-value Program: 0.9688679195443053\n",
      "F-statistic Experience: 1.0742996345919718\n",
      "p-value Experience: 0.3103072795076564\n",
      "F-statistic Interaction: 0.19732034104750384\n",
      "p-value Interaction: 0.8222460450852132\n"
     ]
    }
   ],
   "source": [
    "#10.\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = pd.DataFrame({'Program': ['A', 'B', 'C'] * 10,\n",
    "                     'Experience': ['Novice', 'Experienced'] * 15,\n",
    "                     'Time': [10, 12, 15, 14, 13, 16, 18, 20, 17, 19,\n",
    "                              11, 13, 14, 16, 15, 17, 20, 22, 19, 21,\n",
    "                              9, 11, 10, 12, 15, 13, 14, 16, 18, 17]})\n",
    "\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=data).fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "f_stat_program = anova_table['F']['C(Program)']\n",
    "p_value_program = anova_table['PR(>F)']['C(Program)']\n",
    "\n",
    "f_stat_experience = anova_table['F']['C(Experience)']\n",
    "p_value_experience = anova_table['PR(>F)']['C(Experience)']\n",
    "\n",
    "f_stat_interaction = anova_table['F']['C(Program):C(Experience)']\n",
    "p_value_interaction = anova_table['PR(>F)']['C(Program):C(Experience)']\n",
    "\n",
    "print(\"F-statistic Program:\", f_stat_program)\n",
    "print(\"p-value Program:\", p_value_program)\n",
    "\n",
    "print(\"F-statistic Experience:\", f_stat_experience)\n",
    "print(\"p-value Experience:\", p_value_experience)\n",
    "\n",
    "print(\"F-statistic Interaction:\", f_stat_interaction)\n",
    "print(\"p-value Interaction:\", p_value_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d99f8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -7.585740789732326\n",
      "p-value: 2.1164015282622466e-11\n"
     ]
    }
   ],
   "source": [
    "#11.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "control_group = [82, 78, 85, 76, 90, 83, 79, 87, 81, 88, 84, 77, 89, 80, 86, 75, 92, 83, 78, 85,\n",
    "                 79, 87, 81, 88, 84, 77, 89, 80, 86, 75, 92, 83, 78, 85, 79, 87, 81, 88, 84, 77,\n",
    "                 89, 80, 86, 75, 92, 83, 78, 85, 79]\n",
    "\n",
    "experimental_group = [88, 86, 92, 85, 94, 90, 89, 93, 87, 91, 84, 86, 88, 85, 92, 87, 95, 90, 89, 93,\n",
    "                      88, 86, 92, 85, 94, 90, 89, 93, 87, 91, 84, 86, 88, 85, 92, 87, 95, 90, 89,\n",
    "                      93, 88, 86, 92, 85, 94, 90, 89, 93, 87]\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc483fcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m55\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m65\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m f_statistic, p_value \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mf_oneway(data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m                                       data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     10\u001b[0m                                       data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF-statistic:\u001b[39m\u001b[38;5;124m\"\u001b[39m, f_statistic)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#12.\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "data = pd.DataFrame({'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30, 'Sales': [50, 55, 60, 65, 70, 75] * 30})\n",
    "\n",
    "f_statistic, p_value = stats.f_oneway(data[data['Store'] == 'A']['Sales'],\n",
    "                                      data[data['Store'] == 'B']['Sales'],\n",
    "                                      data[data['Store'] == 'C']['Sales'])\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d79be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
